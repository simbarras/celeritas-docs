%%---------------------------------------------------------------------------%%
% performance.tex
%%---------------------------------------------------------------------------%%
\section{\celeritas performance}

Given the range of detector geometry complexities, primary event types, and
amount of output, there is no general case that provides a simple performance
number such as a simulation rate in events per second. Therefore, our ultimate
performance metric will be based on a set of real-world \acs{hep} detector
workflow use cases. \celeritas must run the targeted models at the same fidelity
as the current state of the art but in much less time. In the next sections,  we
will present the two \acp{fom} that will be used to measure success, along with
a few preliminary performance results comparing \celeritas with current state of
the art \ac{mc} codes.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{Performance metrics}

On \ac{lcf} hardware for the next decade, \acp{gpu} will provide the bulk of the
compute capability, so one critical performance metric is the ratio of the
runtime of \celeritas using \acp{gpu} to using only the \acp{cpu} of a given
machine. This \ac{fom} represents the ability of \celeritas to effectively use
the hardware that is available and must be sufficiently high to justify running
on \ac{lcf} resources. We will target a factor of $160\times$ for a single
\ac{gpu} to a single \ac{cpu}, which is the relative \ac{gpu}/\ac{cpu}
performance of the Shift \ac{mc} transport code
\cite{hamilton_continuous-energy_2019}.

A second performance metric is critical to the programmatic viability of
\celeritas in the broader \ac{hep} community: the work done for the same amount
of cost in power consumption and hardware, using Geant4 on \ac{cpu} as a
baseline. This \ac{fom} is the motivation for \ac{hep} workflows to adapt to
using \celeritas for \ac{mc} transport. The Geant4 team supposes that a factor
of two speedup resulting from ``adiabatic improvements'' to their code is not
outside the realm of possibility \cite{marc_verderi_geant4_2021}, so a $2
\times$ cost improvement of \celeritas runtime over Geant4 runtime is our second
target. Assuming that electricity consumption (and waste heat disposal) are the
primary constraints for independent \ac{hep} computing centers, this factor
should be evaluated by comparing the performance of Geant4 on \acp{cpu} with a
comparable power requirement as \celeritas on \acp{gpu}. At the present time,
for example, that comparison might be for an AMD 3rd Gen EPYC Processor power
(\SI{280}{\watt} for 64 cores) to a PCIe \nvidia A100 (\SI{250}{\watt} for 108
symmetric multiprocessors).

Meeting these \acp{fom} with Geant4-equivalent physics capabilities and
providing a solid user interface and \ac{io} integration to \ac{hep} workflows
will be the ultimate confirmation that \celeritas is a viable option for
\ac{hep} experiments. At this point \celeritas will be ideal for execution on
\ac{doe} \acp{lcf} and will be sufficiently fast on its own merits to motivate
independent adoption on capacity systems.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{Preliminary results}

\celeritas will develop a series of internal test problems to validate every
aspect of the code, including physics, geometry, \ac{em} fields, and \ac{io}.
Here, we present a small set of preliminary results comparing \celeritas against
Geant4 and \acs{adept}. These results are produced using the \emph{TestEm3}
example, available in \acs{adept}'s repository\footnote
{
    \url{https://github.com/apt-sim/AdePT}
},
which is a geometry composed by 50 rectangular layers, each composed by an
absorber and a gap made of Pb and liquid Ar.

In order to run a comparison between the three codes, we ported the
\acs{adept}'s implementation of the \emph{TestEm3} geometry to a Geant4
application, which in turn exported the geometry as a \acs{gdml} file, which is
the current default input used by \celeritas. All three applications are running
the same physics models with the same secondary production thresholds. The main
caveats here are the use of different \acp{prng}, and the fact that Geant4 uses
its own navigation system, whereas \celeritas and \acs{adept} rely on
\acs{vecgeom}.

The results are produced using a particle-gun type input with \num{100000}, 10
GeV, electron primaries placed before the first layer. Their momentum direction
is fixed and pointed perpendicularly towards the layers. The device used is
similar to \ac{olcf}'s Summit: it has Intel Xeon Gold 5218 (Cascade Lake)
\acp{cpu} running at 2.3GHz (2 sockets of 16 cores with 2 hardware threads per
core, with \SI{188}{\giga\byte} total memory), and \nvidia V100 \acp{gpu} (each
with 80 symmetric multiprocessors, 64 CUDA cores per multiprocessor, and
\SI{16}{\giga\byte} memory). The current physics equivalency relies only on the
mean deposited energy per layer (Fig.~\ref{fig:testem3-edep}), which shows all
codes to be in good agreement. The performance is measured in events per
second---where an event here is one primary particle---and presented in
table~\ref{tab:testem3-performance}. \celeritas shows a speed-up factor of blah
when compared to Geant4, and is bleh faster than \acs{adept}. If \celeritas is
run on CPU, it is still bloh faster than Geant4.

\begin{figure}
    \centering
    %\includegraphics[width=0.5\textwidth]{figs/testem3-edep.pdf}
    \caption{Mean energy deposition per layer, represented by integer numbers
    in the $x$ axis. Each layer is composed by a pair of absorber and gap made
    of Pb and liquid Ar.}
    \label{fig:testem3-edep}
\end{figure}

\begin{table}
    \caption{Comparison between \celeritas, \acs{adept}, and Geant4 performances
    in events per second.}
    \label{tab:testem3-performance}
    \centering
    \begin{tabular}{llrr}
        \toprule
        Application & Execution & Performance [events/s] & Speed-up factor\\
        \midrule
        Geant4      & \ac{cpu} (serial) & 10 & 1\\
        \acs{adept} & \ac{gpu}          & 10 & 1\\
        \celeritas  & \ac{gpu}          & 10 & 1\\
        \celeritas  & \ac{cpu} (serial) & 10 & 1\\
        \bottomrule
    \end{tabular}
  \end{table}
