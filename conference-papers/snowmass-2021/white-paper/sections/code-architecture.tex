%%---------------------------------------------------------------------------%%
% code-architecture.tex
%%---------------------------------------------------------------------------%%
\section{Code Architecture}

A detailed description of the \celeritas code architecture is given in
\textcite{johnson_2021}. The code base (Fig.~\ref{fig:celeritas-code-base})
relies on external dependencies for key capabilities that will be discussed over the next sections.
%%
\begin{figure}
  \centering
  \includegraphics[scale=.6]{figs/software-deps.pdf}
  \caption{\celeritas code base (white) and its existing (gray) and proposed
    (magenta) third-party dependencies, both required (solid lines) and optional
    (dashed lines).}
  \label{fig:celeritas-code-base}
\end{figure}
%%

\celeritas supports intra-node concurrency on multi-core architectures through
\acs{openmp} and on \nvidia \acp{gpu} using \cuda, which we plan to supplement
with a programming model for vendor-independent portability.  Internode
parallelism is currently implemented using the \ac{mpi} communication library
through a domain replication model in which particle events are decomposed
across \ac{mpi} ranks.

Like other \ac{gpu}-enabled \ac{mc} transport codes such as Shift
\cite{pandya_implementation_2016,hamilton_multigroup_2018,
hamilton_continuous-energy_2019,hamilton_domain_2022}, the low-level component
code used by transport kernels is designed so that each particle track
corresponds to a single thread. There is no cooperation between individual
threads, facilitating the dual host/device annotation of most of \celeritas.
\celeritas also uses a modular programming approach based on composition rather
than inheritance in order to accommodate device-based architectures, which have
poor support for runtime polymorphism.  Furthermore, the use of simple classes
that define function-object interfaces enables lambda semantics for kernel
launches. These features will simplify the adaptation to a performance
portability model.

The \celeritas programming model uses the \ac{dop} paradigm \cite{dop_2022} to
facilitate platform portability, improve memory access patterns, and accelerate
development. \ac{dop} separates execution code from data, and as part of this
model \celeritas carefully partitions immutable, shared ``parameter'' data from
dynamic thread-local ``state'' data. Object-oriented design patterns encapsulate
the data storage implementation, temporarily combining parameter and state data
into ``view'' classes.  Higher-level classes use composition to combine the data
from the multiple entities that comprise a particle track's complete state.

In the first 1.5 years of \celeritas' development, nine \ac{gpu}-compatible
physics models (Table~\ref{tab:em-physics}) have been implemented. This shows
\ac{dop} to be highly effective for development on heterogeneous architectures
that have independent \emph{memory spaces} between which data must be
transferred. One challenge faced by \ac{mc} physics application codes is the
ubiquity of complicated \emph{heterogeneous} data structures needed for
tabulated physics and particle data, as opposed to the simpler
\emph{homogeneous} data layouts required by deterministic numerical solvers. A
novel programming model in \celeritas enables the composition of new, deep data
types (e.g., material properties) that are required by geometric and physics
operations during the transport loop without fragmenting the underlying data
layout on device.

One requirement for transporting particles in \ac{em} showers is the efficient
allocation and construction of secondary particles during a physics interaction.
On \acp{gpu}, managing dynamic allocations efficiently is a significant
challenge.  To enable runtime dynamic allocation of secondary particles, we have
developed a function-like stack allocator that accesses a large on-device
allocated array with a fixed capacity and uses an atomic addition to
unambiguously reserve one or more items in the array. The final aspect of
\ac{gpu}-based secondary allocation is how to gracefully handle an out-of-memory
condition without crashing the simulation \emph{or} invalidating its
reproducibility. A novel algorithm in \celeritas guarantees robustness when
allocating secondaries, which we will extend to guarantee complete
reproducibility of \ac{hep} workflow results.

The \celeritas code architecture just summarized is designed to enable \ipl{1}
performance portability, \ipl{2} implementation of new physics models and
processes, \ipl{3} optimal geometric tracking, \ipl{4} optimization of the
particle transport algorithm in the presence of external \ac{em} fields, and
\ipl{5} addition of scoring and \ac{ui} necessary to meet \acs{hep} detector
simulation requirements.
