%%---------------------------------------------------------------------------%%
% integration.tex
%%---------------------------------------------------------------------------%%
\section{Integration with \ac{hep} workflows}

\ac{doe} \acp{lcf} are planned to be part of \ac{hep} workflows by the
scientific community, with their use ranging from simulation and reconstruction
to \ac{ai} methods \cite{hep-network-requirements}. While the Cosmic Frontier is
already taking advantage of facilities such as \ac{alcf}, \ac{nersc}, and
\ac{olcf}, the Energy and Intensity Frontiers have less clear integrations
pathways. \celeritas aims close the gap between \ac{hep} distributed computing
networks and \acp{lcf} networks by providing three different routes
(Fig.~\ref{fig:celeritas-hep-workflows}).
%%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/celeritas_integration-all}
    \caption{Proposed \acs{hep} integration workflows for (a) \acceleritas, (b)
    end-to-end \celeritas, and (c) \celeritas for \acs{ai}.}
    \label{fig:celeritas-hep-workflows}
\end{figure}
%%
These workflows intend to enable \ac{hep} experiments to use \celeritas in three
different ways:
%%
\begin{enumerate}[itemsep=0pt, label=(\alph*)]
  \item \emph{Acceleritas}: accelerate standard \ac{hep} detector simulation
    workflows built on Geant4 by offloading \ac{em} particle showers to
    \acp{gpu} using a new \acceleritas library.
  \item \emph{End-to-end}: run complete end-to-end detector simulations with
    comprehensive \ac{sm} physics at the \acp{lcf}.
  \item \emph{\ac{ai}}: generate high-resolution detector responses as training
    data for \ac{ai} networks to be deployed at experimental facilities as
    software triggers and surrogate models.
\end{enumerate}
%%
The next sections will discuss expected challenges and mitigation strategies,
and describe these three envisioned plans to integrate \celeritas into
experimental workflows. Since each workflow has unique traits, we expect that
some experimental collaborations might see value in using all three workflows,
each serving a different purpose.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{Integration challenges}

The heterogeneity of \ac{hep} computing workflows, associated with the volume of
data produced by each experiment, pose a long list of challenges that need to be
overcome in order to make \celeritas a viable option. We outline here the most
pressing ones, along with mitigation plans. 
%%
\begin{enumerate}[itemsep=0pt]
  \item Simulation inputs must be flexible enough to encompass Energy and
    Intensity Frontier needs. This includes user-defined geometry, physics,
    events, secondary particle cutoff thresholds, and sensitive detector scoring
    regions.
  \item Output data, which entails \ac{mc} particle history and detector
    scoring, should be flexible enough to make it compatible to experimental
    workflows, while maximizing \ac{io} efficiency.
  \item End-user interface must be simple enough such that the performance gain
    and the work needed to adapt experimental computing workflows justify the
    adoption.
  \item Domestic and international networking between \acp{lcf} and \ac{hep}
    computing centers can lead to large data migration which can result in
    network congestions and suboptimal resource usage.  The \ac{lhc}'s ``any
    data, anywhere, anytime'' model \cite{hep-network-requirements} might need
    special attention.
\end{enumerate}

These main challenges, among other topics, will be discussed and addressed via a
\celeritas \emph{User Council}, which will be formed by members of different
\ac{hep} experiments on both Energy and Intensity Frontiers. The incorporation
\celeritas workflows into existing experimental simulation frameworks will
require early engagement with the experiments. Thus, interactions with the
\emph{User Council} will determine the tradeoffs of applying \celeritas and
\acp{lcf} to their \ac{mc} production, as well as advise the \celeritas team
when developing end-user interfaces, such that the code develops focusing on
experimental compatibility.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{Acceleritas}
\label{sec:acceleritas}

\acceleritas (Fig.~\ref{fig:celeritas-hep-workflows}a) is a library that will
provide a hybrid workflow between \celeritas and Geant4. It leverages the Geant4
tasking manager system to transfer parts of the simulation to \celeritas for
concurrent execution on device. That will allow a Geant4-based \ac{hep} detector
simulation to collect a subset of particles from either primary collisions or
subsequent hadronic interactions and transport them in parallel on the device
using \celeritas while processing the remainder on the host using Geant4.  The
initial group of offloaded particles will be photons, electrons, and positrons,
but selected hadronic physics will be conditionally integrated based on the
performance of \acceleritas.

The Geant4 tasking manager is responsible for handling all of the major steps in
the process, which includes collecting the list of particles to be offloaded,
launching the \celeritas on-device transport loop, and merging sensitive hits
and particle track data from the device back to Geant4 on the host.

Using Amdahl's law, we expect that the maximum gain of an \acceleritas
application is $1/(1-f)$, where $f$ is the fraction of offloaded work in a
\ac{cpu}-only calculation.  For typical \ac{hep} events at \acs{hllhc} and with
the \ac{cms} detector geometry, the maximum speed-up will be roughly a factor 3
for offloading photons and electrons to \acp{gpu} as their fractional \ac{cpu}
contribution is around 70\%.

These gains are nowhere near our expected goals for a full end-to-end \celeritas
simulation, where we expect \celeritas to achieve a similar 160$\times$ speedup
factor observed in Shift. Nevertheless, \acceleritas will provide significant
improvements while requiring minimal adapations on current \ac{hep} workflows.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{End-to-end \celeritas}
\label{sec:end-to-end}

\emph{End-to-end} \celeritas integration
(Fig.~\ref{fig:celeritas-hep-workflows}b) requires a mature \celeritas code,
which will rely on the implementation of comprehensive \ac{sm} physics
capabilities along with a fully operational \ac{io} system, including the
possibility to run digitization still at the \acp{lcf}. This incorporation of
\celeritas workflows into existing experimental simulation frameworks will
require early engagement with experiments, and thus depends on a successful
creation and interaction between the \celeritas team with members of the
\emph{User Council}.

An experimental workflow characteristic that will have to be assessed is related
to how event-processing systems are handled on \ac{cpu} and \ac{gpu}. The most
efficient interface would fully occupy the device by executing many events
concurrently.  However, this is not the way that experimental workflows are
currently configured, in which events are executed independently on each thread.
A more seamless integration of the end-to-end workflow would be to preserve
independent event execution.  However, this will have a dramatic effect on the
achievable performance because the \ac{gpu} will have to accumulate sufficient
tracks to fully occupy the device.

The tradeoffs between performance and integration cost will be discussed and
ultimately decided by the experimental collaborations. Finally, the volume of
data transferred between \acp{lcf} and \ac{hep} computing networks is a concern
that will require attention as the project evolves.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %
\subsection{\celeritas for \ac{ai}}
\label{sec:celeritas-ai}

\ac{ai} methods are now essential in experimental \ac{hep}, with efforts to
unify standard \ac{ai} frameworks with \ac{hep} workflows \cite{mlaas4hep}. The
use of \ac{ai} has been succesfully deployed in detector triggering
\cite{ml-trigger}, training surrogate models \cite{fastcalogan}, hit and
image-based reconstruction algorithms \cite{gnn-reco-cms,jets-deep-learning},
and selection of candidate events in data analyses \cite{cvn-nova}. All of these
applications require extensive generation of data for training new networks
before their deployment and, as these techniques are very data and process
intensive, their training can significantly impact \ac{hep} distributed
computing network resources.

With increasing use of \ac{ai} within \ac{hep}, we envision \celeritas and
\acp{lcf} as tools to produce fast, full-fidelity \ac{mc} samples for the
purpose of training new \ac{ai} networks and alleviate the workload on \ac{hep}
computing centers. Standard \ac{ai} frameworks already take advantage of
accelerated architectures, making \celeritas an ideal tool for using \acp{lcf}
as processing centers for \ac{ai} applications in \ac{hep}.
